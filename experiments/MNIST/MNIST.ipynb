{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K98KPqrddb9u"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from models_dif import SoftmaxWeight, LocationScaleFlow, DIFDensityEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###MNIST###\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "images = mnist_trainset.data.flatten(start_dim=1).float()\n",
    "temp = (images + torch.rand_like(images))/256\n",
    "\n",
    "def pre_process(x, lbda):\n",
    "    return torch.logit(lbda*torch.ones_like(x) + x*(1-2*lbda))\n",
    "\n",
    "def inverse_pre_process(x, lbda):\n",
    "    return torch.sigmoid((x- lbda*torch.ones_like(x))/(1-2*lbda))\n",
    "\n",
    "lbda = 1e-6\n",
    "target_samples = pre_process(temp, lbda)\n",
    "p = target_samples.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LocationScaleFlow(nn.Module):\n",
    "    def __init__(self, K, p):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.p = p\n",
    "\n",
    "        self.m = nn.Parameter(torch.randn(self.K, self.p))\n",
    "        self.log_s = nn.Parameter(torch.zeros(self.K, self.p))\n",
    "\n",
    "    def backward(self, z):\n",
    "        desired_size = list(z.shape)\n",
    "        desired_size.insert(-1, self.K)\n",
    "        Z = z.unsqueeze(-2).expand(desired_size)\n",
    "        return Z * torch.exp(self.log_s).expand_as(Z) + self.m.expand_as(Z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        desired_size = list(x.shape)\n",
    "        desired_size.insert(-1, self.K)\n",
    "        X = x.unsqueeze(-2).expand(desired_size)\n",
    "        return (X-self.m.expand_as(X))/torch.exp(self.log_s).expand_as(X)\n",
    "\n",
    "    def log_det_J(self,x):\n",
    "        return -self.log_s.sum(-1)\n",
    "\n",
    "class FullRankLocationScaleFlow(nn.Module):\n",
    "    def __init__(self, K, p):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.p = p\n",
    "\n",
    "        self.m = nn.Parameter(torch.randn(self.K, self.p))\n",
    "        self.chol = torch.eye(self.p).unsqueeze(0).repeat(self.K, 1,1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        desired_size_Z_M = list(z.shape)\n",
    "        desired_size_Z_M.insert(-1, self.K)\n",
    "        desired_size_S = list(z.shape)\n",
    "        desired_size_S.insert(-1, self.K)\n",
    "        desired_size_S.insert(-1, self.p)\n",
    "        return ((self.chol.expand(desired_size_S))@(z.unsqueeze(-2).expand(desired_size_Z_M).unsqueeze(-1))).squeeze(-1) + self.m.expand(desired_size_Z_M)\n",
    "\n",
    "    def backward(self, x):\n",
    "        desired_size_X_M = list(x.shape)\n",
    "        desired_size_X_M.insert(-1, self.K)\n",
    "        desired_size_S = list(x.shape)\n",
    "        desired_size_S.insert(-1, self.K)\n",
    "        desired_size_S.insert(-1, self.p)\n",
    "        return ((torch.inverse(self.chol).expand(desired_size_S))@((x.unsqueeze(-2).expand(desired_size_X_M)-self.m.expand(desired_size_X_M)).unsqueeze(-1))).squeeze(-1)\n",
    "\n",
    "    def log_det_J(self):\n",
    "        S = self.chol\n",
    "        return torch.log(torch.diagonal(S,0,1,2)).sum(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 784, 784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 61465600000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-405d50f39e66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#dif.T.chol = torch.cholesky(torch.cov(target_samples.T)).unsqueeze(0).repeat(K,1,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_density_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size)\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_density_estimator.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_density\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_det_J\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ef4e1d9cd45b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mdesired_size_S\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mdesired_size_S\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesired_size_S\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesired_size_Z_M\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesired_size_Z_M\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 61465600000 bytes."
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "dif = DIFDensityEstimator(target_samples, K)\n",
    "dif.T  = FullRankLocationScaleFlow(K,p)\n",
    "dif.T.m = torch.nn.Parameter(torch.mean(target_samples).unsqueeze(0).repeat(K,1) + 0.001*torch.rand(K,p))\n",
    "#dif.T.chol = torch.cholesky(torch.cov(target_samples.T)).unsqueeze(0).repeat(K,1,1)\n",
    "print(dif.T.chol.shape)\n",
    "dif.train(200, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.train(2000, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize training ###\n",
    "model_to_visualize = dif\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "\n",
    "loss_values = dif.loss_values\n",
    "best_loss = min(loss_values)\n",
    "best_iteration = loss_values.index(best_loss)\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = plt.subplot(111)\n",
    "Y1, Y2 = best_loss - (max(loss_values) -best_loss) / 2, max(loss_values) + (max(loss_values) - best_loss) / 4\n",
    "ax.set_ylim(Y1, Y2)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.plot(loss_values, label='Loss values during training', color='black')\n",
    "ax.scatter([best_iteration], [best_loss], color='black', marker='d')\n",
    "ax.axvline(x=best_iteration, ymax=(best_loss -best_loss + (max(loss_values) - best_loss) / 2) / (\n",
    "        max(loss_values) + (max(loss_values) - best_loss) / 4 - best_loss + (\n",
    "        max(loss_values) - best_loss) / 2), color='black', linestyle='--')\n",
    "ax.text(0, best_loss - (max(loss_values) - best_loss) / 8,\n",
    "        'best iteration = ' + str(best_iteration) + '\\nbest loss = ' + str(np.round(best_loss, 5)),\n",
    "        verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "if len(loss_values) > 30:\n",
    "    x1, x2 = best_iteration - int(len(loss_values) / 15), min(best_iteration + int(len(loss_values) / 15),\n",
    "                                                              len(loss_values) - 1)\n",
    "    k = len(loss_values) / (2.5 * (x2 - x1 + 1))\n",
    "    offset = (Y2 - Y1) / (6 * k)\n",
    "    y1, y2 = best_loss - offset, best_loss + offset\n",
    "    axins = zoomed_inset_axes(ax, k, loc='upper right')\n",
    "    axins.axvline(x=best_iteration, ymax=(best_loss - y1) / (y2 - y1), color='black', linestyle='--')\n",
    "    axins.scatter([best_iteration], [best_loss], color='black', marker='d')\n",
    "    axins.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    axins.plot(loss_values, color='black')\n",
    "    axins.set_xlim(x1 - .5, x2 + .5)\n",
    "    axins.set_ylim(y1, y2)\n",
    "    mark_inset(ax, axins, loc1=3, loc2=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(50):\n",
    "        plt.figure()\n",
    "        sample = dif.sample_model(1)\n",
    "        plt.imshow(sample[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DUAN TMC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
