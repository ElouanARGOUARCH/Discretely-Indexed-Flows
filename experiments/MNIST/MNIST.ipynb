{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K98KPqrddb9u"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from models_dif import SoftmaxWeight, LocationScaleFlow, DIFDensityEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0942)\n",
      "number of samples = 60000\n",
      "tensor([3.1972e-03, 3.8586e-03, 2.8623e-03, 5.0513e-05, 3.2003e-03, 5.0001e-04,\n",
      "        2.2858e-03, 3.7022e-03, 3.0302e-03, 3.6327e-03, 2.7909e-03, 2.1474e-03,\n",
      "        3.3343e-03, 1.1930e-03, 3.2053e-03, 4.0668e-04, 1.0651e-03, 1.1124e-04,\n",
      "        2.9299e-03, 6.9026e-04, 1.8230e-03, 3.8402e-03, 2.4997e-03, 1.8137e-03,\n",
      "        1.7212e-03, 2.0314e-03, 2.4504e-03, 1.1550e-03, 1.4260e-03, 2.1283e-03,\n",
      "        1.7552e-03, 9.2713e-04, 1.4443e-03, 1.8400e-03, 3.8472e-03, 8.1574e-05,\n",
      "        3.6368e-03, 2.4701e-03, 3.8315e-03, 3.7169e-03, 3.2193e-03, 3.3188e-03,\n",
      "        1.2827e-03, 2.3775e-03, 2.4324e-03, 2.1070e-03, 1.9327e-03, 2.9816e-03,\n",
      "        1.3883e-04, 3.6135e-03, 1.2321e-03, 3.1508e-03, 3.1973e-04, 3.4623e-03,\n",
      "        4.3329e-04, 1.7818e-03, 2.4053e-03, 3.5908e-03, 3.5316e-03, 5.4132e-04,\n",
      "        2.0624e-03, 3.0558e-03, 2.7510e-03, 2.0032e-03, 2.4676e-03, 1.0724e-03,\n",
      "        3.3830e-03, 5.8862e-04, 1.6980e-03, 8.8172e-04, 2.8299e-03, 1.9552e-03,\n",
      "        3.3989e-03, 2.3401e-03, 1.8486e-03, 1.5177e-03, 5.4276e-04, 2.6765e-03,\n",
      "        5.9272e-04, 9.2706e-04, 2.2359e-03, 1.1189e-03, 1.7191e-04, 2.4376e-03,\n",
      "        2.9245e-03, 2.4326e-03, 9.6850e-04, 3.0752e-03, 2.5977e-03, 2.5175e-03,\n",
      "        3.4690e-03, 1.6780e-04, 1.5086e-03, 2.8671e-04, 3.4301e-03, 2.1951e-03,\n",
      "        7.9321e-04, 2.8957e-04, 3.6886e-03, 3.0447e-03, 6.8746e-05, 3.6637e-03,\n",
      "        6.6564e-04, 3.3502e-03, 1.7110e-03, 3.3697e-03, 2.7301e-03, 4.0648e-04,\n",
      "        4.3879e-05, 5.6800e-04, 7.1474e-04, 3.6246e-03, 1.9847e-03, 1.1549e-03,\n",
      "        1.9087e-03, 3.3968e-03, 9.7687e-04, 3.4554e-03, 8.5749e-04, 9.1136e-04,\n",
      "        1.3825e-03, 3.8465e-03, 3.6321e-03, 1.8511e-03, 2.0685e-03, 3.7230e-03,\n",
      "        2.3775e-03, 3.5145e-03, 2.6831e-03, 6.6431e-04, 1.2606e-03, 2.6762e-03,\n",
      "        1.6572e-03, 3.4384e-03, 2.7664e-03, 1.8933e-03, 7.1182e-04, 2.6014e-03,\n",
      "        6.1219e-04, 1.4544e-03, 1.2135e-03, 5.9749e-04, 1.8376e-03, 2.6575e-03,\n",
      "        2.3763e-03, 8.4179e-04, 8.2283e-04, 1.4530e-03, 3.3120e-03, 3.4035e-04,\n",
      "        3.6277e-03, 5.5381e-04, 1.3041e-02, 7.2693e-02, 7.1004e-02, 7.1851e-02,\n",
      "        4.9513e-01, 5.3212e-01, 6.8652e-01, 1.0523e-01, 6.4952e-01, 9.9917e-01,\n",
      "        9.6845e-01, 4.9656e-01, 1.2910e-03, 3.7711e-03, 5.5964e-04, 3.5863e-03,\n",
      "        1.2509e-03, 2.7082e-03, 5.0215e-04, 1.3541e-03, 3.6563e-03, 9.3121e-04,\n",
      "        1.8110e-03, 2.0530e-03, 1.2027e-01, 1.4400e-01, 3.6882e-01, 6.0344e-01,\n",
      "        6.6677e-01, 9.8943e-01, 9.9042e-01, 9.8973e-01, 9.9019e-01, 9.9128e-01,\n",
      "        8.7968e-01, 6.7549e-01, 9.9044e-01, 9.4754e-01, 7.6343e-01, 2.5321e-01,\n",
      "        1.3591e-03, 2.6304e-03, 9.6830e-04, 3.7362e-03, 1.1382e-03, 1.2442e-03,\n",
      "        2.4750e-04, 9.1284e-04, 1.0387e-03, 3.1021e-03, 3.4256e-03, 1.9176e-01,\n",
      "        9.3286e-01, 9.8845e-01, 9.9021e-01, 9.9086e-01, 9.8837e-01, 9.8895e-01,\n",
      "        9.9071e-01, 9.9074e-01, 9.8893e-01, 9.8356e-01, 3.6422e-01, 3.2130e-01,\n",
      "        3.2206e-01, 2.1978e-01, 1.5513e-01, 5.2536e-04, 1.2499e-03, 1.3431e-03,\n",
      "        4.0574e-04, 1.0405e-03, 1.7701e-03, 3.1272e-03, 2.2384e-03, 3.1806e-03,\n",
      "        2.9174e-03, 3.4644e-05, 2.0649e-03, 7.0669e-02, 8.5555e-01, 9.9121e-01,\n",
      "        9.8841e-01, 9.8879e-01, 9.8907e-01, 9.8850e-01, 7.7545e-01, 7.1160e-01,\n",
      "        9.6523e-01, 9.4422e-01, 9.3720e-04, 2.8948e-03, 2.6506e-03, 1.7435e-03,\n",
      "        2.4253e-03, 7.7336e-04, 3.0711e-03, 1.3431e-03, 3.0622e-03, 2.5195e-03,\n",
      "        1.7933e-03, 2.9174e-03, 3.1147e-03, 3.6699e-04, 3.2015e-03, 2.9790e-03,\n",
      "        2.8522e-03, 2.9130e-03, 3.1599e-01, 6.1293e-01, 4.1961e-01, 9.8917e-01,\n",
      "        9.8834e-01, 8.0259e-01, 4.4060e-02, 2.1208e-03, 1.6955e-01, 6.0188e-01,\n",
      "        7.4249e-04, 1.3358e-03, 1.9010e-03, 3.7600e-03, 7.8665e-05, 8.7634e-05,\n",
      "        2.4901e-03, 2.4186e-03, 2.7648e-04, 2.1472e-03, 1.5339e-03, 1.8753e-04,\n",
      "        2.6972e-03, 5.4845e-05, 3.7495e-03, 8.5186e-04, 3.7256e-03, 6.8217e-04,\n",
      "        3.4292e-03, 5.6969e-02, 4.4888e-03, 6.0545e-01, 9.8871e-01, 3.5186e-01,\n",
      "        2.8180e-03, 3.5335e-03, 3.5905e-03, 1.9037e-03, 3.8725e-03, 2.5978e-03,\n",
      "        3.2673e-04, 2.7103e-03, 3.2713e-03, 1.0777e-03, 2.6480e-03, 2.0892e-04,\n",
      "        3.4392e-03, 4.3213e-04, 2.7735e-03, 8.1914e-04, 1.9720e-04, 5.2234e-05,\n",
      "        8.6468e-04, 3.8592e-03, 9.2185e-04, 3.2002e-03, 4.0829e-05, 3.6371e-03,\n",
      "        2.8794e-03, 5.4354e-01, 9.8852e-01, 7.4411e-01, 8.7032e-03, 1.4841e-03,\n",
      "        2.7339e-03, 9.9825e-04, 5.0886e-04, 9.1447e-04, 7.3709e-04, 1.7076e-03,\n",
      "        6.7803e-04, 1.1904e-03, 3.2831e-03, 3.7254e-03, 1.5330e-03, 2.2166e-03,\n",
      "        3.7200e-03, 7.5596e-04, 8.9317e-04, 2.8658e-03, 5.4873e-04, 1.2879e-03,\n",
      "        3.4399e-03, 1.9699e-03, 2.7267e-03, 3.2339e-03, 6.7073e-04, 4.5960e-02,\n",
      "        7.4467e-01, 9.9028e-01, 2.7693e-01, 3.7747e-03, 1.5977e-03, 3.8370e-03,\n",
      "        5.2755e-04, 1.2734e-03, 7.4165e-04, 2.5778e-03, 8.7661e-06, 2.9218e-03,\n",
      "        1.6024e-03, 3.4529e-03, 3.8211e-03, 3.8982e-04, 1.1995e-03, 3.3217e-03,\n",
      "        2.0615e-03, 2.7020e-03, 1.0105e-03, 2.0513e-03, 3.4152e-03, 3.1692e-03,\n",
      "        2.5435e-03, 1.3273e-03, 2.8474e-03, 9.6112e-04, 1.3977e-01, 9.4275e-01,\n",
      "        8.8136e-01, 6.2744e-01, 4.2293e-01, 6.7168e-03, 1.3119e-03, 2.2439e-03,\n",
      "        2.4917e-03, 3.2889e-03, 1.9574e-03, 9.6401e-04, 2.5831e-03, 2.8654e-03,\n",
      "        3.4982e-03, 1.4850e-03, 2.8279e-03, 2.5644e-03, 9.1203e-04, 1.2668e-03,\n",
      "        1.5416e-04, 2.5939e-03, 2.2953e-03, 2.1714e-03, 8.1884e-05, 2.3687e-03,\n",
      "        2.8358e-03, 2.6910e-03, 3.3192e-03, 3.1652e-01, 9.3961e-01, 9.8935e-01,\n",
      "        9.9097e-01, 4.6619e-01, 9.9059e-02, 2.1075e-03, 1.5183e-03, 2.7940e-03,\n",
      "        3.2802e-03, 1.2058e-03, 3.8554e-03, 3.3912e-03, 2.6655e-03, 2.0499e-03,\n",
      "        7.5925e-05, 3.8243e-03, 2.5126e-04, 4.8650e-05, 1.0215e-03, 3.6784e-03,\n",
      "        2.6850e-03, 3.1089e-03, 3.3079e-03, 1.1666e-03, 3.0963e-03, 3.1715e-03,\n",
      "        3.8571e-03, 3.4554e-03, 1.7860e-01, 7.2989e-01, 9.8894e-01, 9.8950e-01,\n",
      "        5.8754e-01, 1.0877e-01, 1.3388e-03, 2.3139e-03, 2.5701e-03, 1.8799e-03,\n",
      "        2.0081e-03, 2.9447e-03, 2.9379e-03, 5.5739e-04, 3.6155e-03, 2.4679e-03,\n",
      "        1.6742e-03, 3.8750e-03, 3.5266e-03, 3.0738e-03, 3.2322e-03, 1.5214e-03,\n",
      "        3.3442e-03, 1.5548e-03, 6.9719e-04, 7.1620e-04, 3.1429e-04, 2.1705e-03,\n",
      "        2.0338e-03, 6.3992e-02, 3.6419e-01, 9.8572e-01, 9.8894e-01, 7.3269e-01,\n",
      "        2.3710e-04, 2.4462e-03, 3.7113e-03, 6.8318e-04, 2.6117e-03, 1.5501e-03,\n",
      "        2.6339e-03, 1.6457e-03, 3.4482e-03, 8.1306e-04, 2.6351e-03, 1.2955e-03,\n",
      "        1.4286e-03, 2.8334e-03, 2.6088e-03, 1.9131e-03, 1.6684e-03, 2.5713e-03,\n",
      "        2.6258e-03, 1.7200e-03, 3.8192e-03, 1.9640e-03, 6.6272e-04, 1.0352e-03,\n",
      "        2.5991e-03, 9.7520e-01, 9.8878e-01, 9.7436e-01, 2.5240e-01, 9.2470e-04,\n",
      "        3.6266e-03, 3.2902e-03, 2.5569e-03, 1.7523e-03, 1.5593e-03, 3.5546e-03,\n",
      "        1.3887e-03, 3.8657e-03, 1.8105e-03, 2.5488e-03, 2.9205e-03, 2.5664e-03,\n",
      "        1.3101e-03, 8.2052e-04, 3.7003e-03, 1.9923e-03, 1.9089e-03, 1.5378e-03,\n",
      "        3.2033e-03, 3.4299e-03, 1.8231e-01, 5.1030e-01, 7.1669e-01, 9.9170e-01,\n",
      "        9.8964e-01, 8.0869e-01, 9.1361e-03, 3.0564e-03, 2.2036e-03, 2.2747e-03,\n",
      "        6.3177e-04, 3.6049e-03, 2.9307e-03, 1.6389e-04, 2.2658e-03, 8.9895e-04,\n",
      "        5.7785e-04, 3.6804e-03, 7.2538e-04, 6.6432e-04, 3.5848e-03, 2.6842e-03,\n",
      "        3.5412e-03, 2.0311e-03, 1.6046e-03, 3.2103e-03, 1.5347e-01, 5.8037e-01,\n",
      "        8.9492e-01, 9.9069e-01, 9.9123e-01, 9.9105e-01, 9.7999e-01, 7.1408e-01,\n",
      "        4.3708e-04, 2.8248e-03, 1.7054e-03, 3.5627e-03, 2.9674e-04, 3.8304e-03,\n",
      "        2.3368e-03, 1.9127e-03, 2.8309e-03, 2.7948e-04, 2.5499e-03, 2.6765e-03,\n",
      "        3.7281e-03, 1.0632e-03, 2.6189e-03, 3.7103e-03, 6.1299e-05, 2.9171e-03,\n",
      "        9.5678e-02, 4.4743e-01, 8.6452e-01, 9.9149e-01, 9.9079e-01, 9.9014e-01,\n",
      "        9.9136e-01, 7.8648e-01, 3.0725e-01, 1.4773e-03, 3.7871e-03, 1.5947e-03,\n",
      "        1.6211e-03, 2.8105e-03, 3.1085e-03, 2.3928e-03, 6.3068e-04, 1.7883e-03,\n",
      "        2.3906e-03, 1.5083e-03, 1.8669e-03, 1.8986e-03, 3.2829e-03, 3.7042e-03,\n",
      "        3.6573e-03, 3.4894e-03, 9.3523e-02, 2.6130e-01, 8.3521e-01, 9.9057e-01,\n",
      "        9.8900e-01, 9.9145e-01, 9.8969e-01, 7.7650e-01, 3.1939e-01, 1.0882e-02,\n",
      "        4.8503e-04, 9.0803e-05, 2.8425e-03, 2.8983e-03, 1.8300e-03, 3.0807e-03,\n",
      "        3.5599e-04, 3.7117e-03, 1.2614e-03, 1.9223e-03, 1.3437e-04, 3.3964e-03,\n",
      "        3.2796e-03, 2.8457e-03, 3.0770e-03, 1.0121e-03, 7.0403e-02, 6.6880e-01,\n",
      "        8.5834e-01, 9.8909e-01, 9.8985e-01, 9.8843e-01, 9.8946e-01, 7.6546e-01,\n",
      "        3.1579e-01, 3.7117e-02, 3.3287e-03, 1.4319e-04, 2.3114e-03, 2.8297e-03,\n",
      "        8.6986e-04, 1.4138e-03, 1.0710e-03, 6.1305e-04, 3.0219e-03, 1.3507e-03,\n",
      "        3.0962e-03, 1.4950e-03, 4.8408e-04, 2.3368e-03, 9.8784e-04, 2.0560e-04,\n",
      "        2.1613e-01, 6.7397e-01, 8.8437e-01, 9.9006e-01, 9.8886e-01, 9.9187e-01,\n",
      "        9.8855e-01, 9.5475e-01, 5.2127e-01, 4.3509e-02, 1.0123e-03, 2.7901e-04,\n",
      "        9.4631e-04, 1.3552e-03, 8.0043e-04, 2.0592e-03, 9.4946e-05, 2.0049e-03,\n",
      "        2.5311e-03, 3.1157e-03, 1.6211e-03, 3.3772e-03, 1.9784e-03, 8.3395e-04,\n",
      "        8.3504e-04, 4.9403e-04, 3.0939e-03, 1.6011e-03, 5.3493e-01, 9.8860e-01,\n",
      "        9.9024e-01, 9.9026e-01, 8.3201e-01, 5.2808e-01, 5.1632e-01, 6.3981e-02,\n",
      "        3.1387e-03, 3.8583e-03, 8.7774e-04, 3.1312e-03, 2.4997e-03, 2.0455e-03,\n",
      "        3.4472e-03, 2.7806e-03, 3.6594e-03, 1.9045e-03, 2.2626e-05, 3.0229e-03,\n",
      "        6.5043e-04, 2.4935e-03, 3.4275e-03, 1.0255e-03, 1.9081e-03, 3.4604e-03,\n",
      "        8.9919e-04, 3.5890e-03, 2.0081e-03, 2.5718e-03, 3.1101e-03, 8.7611e-04,\n",
      "        1.4014e-03, 2.2267e-03, 1.0089e-03, 3.8810e-04, 1.5641e-03, 2.1781e-03,\n",
      "        4.2287e-04, 5.3862e-04, 1.9932e-03, 4.1958e-04, 2.4195e-03, 1.8159e-03,\n",
      "        2.2538e-03, 2.3074e-03, 2.0494e-03, 4.5041e-06, 1.2195e-03, 1.9777e-03,\n",
      "        1.6571e-03, 2.2311e-03, 2.6057e-03, 3.4412e-03, 9.2218e-04, 3.5085e-03,\n",
      "        3.5970e-03, 8.6348e-04, 2.2643e-03, 1.8601e-03, 2.7785e-04, 1.8062e-03,\n",
      "        3.3041e-03, 1.1529e-03, 4.7375e-05, 2.2301e-03, 2.3175e-03, 3.0772e-03,\n",
      "        2.4989e-03, 2.4391e-03, 2.5804e-03, 1.4375e-03, 3.4598e-03, 3.0724e-03,\n",
      "        2.0863e-03, 1.5552e-03, 3.8729e-03, 4.0984e-05, 2.1468e-03, 6.1978e-04,\n",
      "        1.2325e-03, 3.2688e-03, 8.1005e-04, 1.4090e-03, 1.0877e-04, 4.2261e-05,\n",
      "        5.5780e-04, 2.6565e-03, 2.1225e-03, 3.4263e-03, 3.2055e-03, 1.9331e-03,\n",
      "        2.4927e-03, 7.7984e-04, 3.3030e-03, 2.0629e-03, 4.9071e-04, 1.3556e-03,\n",
      "        2.6738e-03, 3.4756e-03, 3.0686e-03, 1.6652e-03, 1.8128e-03, 2.5766e-03,\n",
      "        3.8016e-03, 2.4003e-03, 3.7845e-04, 2.6117e-04])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###MNIST###\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "images = mnist_trainset.data.flatten(start_dim=1)\n",
    "targets = mnist_trainset.targets\n",
    "\n",
    "digit = 'all'\n",
    "if digit != 'all':\n",
    "    extracted = images[targets == digit].float()\n",
    "else: \n",
    "    extracted = images.float()\n",
    "target_samples = (extracted + torch.rand(extracted.shape))/256\n",
    "print(torch.var(target_samples))\n",
    "\n",
    "num_samples  = target_samples.shape[0]\n",
    "print('number of samples = ' + str(num_samples))\n",
    "p = target_samples.shape[-1]\n",
    "plt.imshow(target_samples[torch.randint(low = 0, high = num_samples, size = [1])].reshape(28,28))\n",
    "\n",
    "train_set, test_set = target_samples[:4000], target_samples[4000:]\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/200 [02:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bb0b9ede5f5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDIFDensityEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSoftmaxWeight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_density_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_density_estimator.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_density\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_det_J\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\multivariate_normal_reference.py\u001b[0m in \u001b[0;36mlog_density\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlog_density\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K = 35\n",
    "dif = DIFDensityEstimator(target_samples, K)\n",
    "dif.w = SoftmaxWeight(K,p, [256,256,256,256])\n",
    "dif.train(200, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif.train(2000, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize training ###\n",
    "model_to_visualize = dif\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "\n",
    "loss_values = dif.loss_values\n",
    "best_loss = min(loss_values)\n",
    "best_iteration = loss_values.index(best_loss)\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = plt.subplot(111)\n",
    "Y1, Y2 = best_loss - (max(loss_values) -best_loss) / 2, max(loss_values) + (max(loss_values) - best_loss) / 4\n",
    "ax.set_ylim(Y1, Y2)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.plot(loss_values, label='Loss values during training', color='black')\n",
    "ax.scatter([best_iteration], [best_loss], color='black', marker='d')\n",
    "ax.axvline(x=best_iteration, ymax=(best_loss -best_loss + (max(loss_values) - best_loss) / 2) / (\n",
    "        max(loss_values) + (max(loss_values) - best_loss) / 4 - best_loss + (\n",
    "        max(loss_values) - best_loss) / 2), color='black', linestyle='--')\n",
    "ax.text(0, best_loss - (max(loss_values) - best_loss) / 8,\n",
    "        'best iteration = ' + str(best_iteration) + '\\nbest loss = ' + str(np.round(best_loss, 5)),\n",
    "        verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "if len(loss_values) > 30:\n",
    "    x1, x2 = best_iteration - int(len(loss_values) / 15), min(best_iteration + int(len(loss_values) / 15),\n",
    "                                                              len(loss_values) - 1)\n",
    "    k = len(loss_values) / (2.5 * (x2 - x1 + 1))\n",
    "    offset = (Y2 - Y1) / (6 * k)\n",
    "    y1, y2 = best_loss - offset, best_loss + offset\n",
    "    axins = zoomed_inset_axes(ax, k, loc='upper right')\n",
    "    axins.axvline(x=best_iteration, ymax=(best_loss - y1) / (y2 - y1), color='black', linestyle='--')\n",
    "    axins.scatter([best_iteration], [best_loss], color='black', marker='d')\n",
    "    axins.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    axins.plot(loss_values, color='black')\n",
    "    axins.set_xlim(x1 - .5, x2 + .5)\n",
    "    axins.set_ylim(y1, y2)\n",
    "    mark_inset(ax, axins, loc1=3, loc2=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(50):\n",
    "        plt.figure()\n",
    "        sample = dif.sample_model(1)\n",
    "        plt.imshow(sample[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DUAN TMC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
