{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_dif import DIFSampler,SoftmaxWeight,LocationScaleFlow\n",
    "from targets.variational_inference_target import *\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "N = 256\n",
    "orange = np.ones((N, 4))\n",
    "orange[:, 0] = np.geomspace(255 / 256, 1, N)  # R = 255\n",
    "orange[:, 1] = np.geomspace(165 / 256, 1, N)  # G = 165\n",
    "orange[:, 2] = np.geomspace(0.001 / 256, 1, N)  # B = 0\n",
    "orange_cmap = ListedColormap(orange[::-1])\n",
    "\n",
    "orange_color = \"#FFA500\"\n",
    "\n",
    "red = np.ones((N, 4))\n",
    "red[:, 0] = np.geomspace(255 / 256, 1, N)  # R = 255\n",
    "red[:, 1] = np.geomspace(0.001 / 256, 1, N)  # G = 0\n",
    "red[:, 2] = np.geomspace(0.001 / 256, 1, N)  # B = 0\n",
    "red_cmap = ListedColormap(red[::-1])\n",
    "\n",
    "red_color = \"#FF0000\"\n",
    "\n",
    "blue = np.ones((N, 4))\n",
    "blue[:, 0] = np.geomspace(0.001 / 256, 1, N)  # R = 0\n",
    "blue[:, 1] = np.geomspace(0.001 / 256, 1, N)  # G = 0\n",
    "blue[:, 2] = np.geomspace(255 / 256, 1, N)  # B = 255\n",
    "blue_cmap = ListedColormap(blue[::-1])\n",
    "\n",
    "blue_color = \"#0000FF\"\n",
    "\n",
    "green = np.ones((N, 4))\n",
    "green[:, 0] = np.geomspace(0.001 / 256, 1, N)  # R = 0\n",
    "green[:, 1] = np.geomspace(128 / 256, 1, N)  # G = 128\n",
    "green[:, 2] = np.geomspace(0.001 / 256, 1, N)  # B = 128\n",
    "green_cmap = ListedColormap(green[::-1])\n",
    "\n",
    "green_color = \"#008000\"\n",
    "\n",
    "pink = np.ones((N, 4))\n",
    "pink[:, 0] = np.geomspace(255 / 256, 1, N)  # R = 255\n",
    "pink[:, 1] = np.geomspace(0.001 / 256, 1, N)  # G = 0\n",
    "pink[:, 2] = np.geomspace(211 / 256, 1, N)  # B = 211\n",
    "pink_cmap = ListedColormap(pink[::-1])\n",
    "\n",
    "pink_color = \"#FF00D3\"\n",
    "\n",
    "purple = np.ones((N, 4))\n",
    "purple[:, 0] = np.geomspace(51 / 256, 1, N)  # R = 102\n",
    "purple[:, 1] = np.geomspace(0.001 / 256, 1, N)  # G = 0\n",
    "purple[:, 2] = np.geomspace(51 / 256, 1, N)  # B = 102\n",
    "purple_cmap = ListedColormap(purple[::-1])\n",
    "\n",
    "purple_color = \"#660066\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def rgb2gray(rgb):\n",
    "    return numpy.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "class image_2d_distribution():\n",
    "    def __init__(self, file):\n",
    "        image = plt.imread(file)\n",
    "        self.image = torch.tensor(rgb2gray(image))\n",
    "        self.vector_density = self.image.flatten()/torch.sum(self.image)\n",
    "        self.lines, self.columns = self.image.shape\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        cat = torch.distributions.Categorical(probs=self.vector_density)\n",
    "        categorical_samples = cat.sample(num_samples)\n",
    "        return torch.cat([((categorical_samples % self.columns + torch.rand(num_samples)) / self.columns).unsqueeze(-1),\n",
    "                                    (\n",
    "                                    (1 - (categorical_samples // self.columns + torch.rand(num_samples)) / self.lines)).unsqueeze(\n",
    "                                        -1)], dim=-1)\n",
    "\n",
    "    def log_prob(self,x):\n",
    "        flattened_x = torch.flatten(x, start_dim = 0, end_dim = -2)\n",
    "        mask = torch.logical_and(torch.all(flattened_x>0, dim= -1),torch.all(flattened_x<1, dim = -1))\n",
    "        selected = flattened_x[mask]\n",
    "        x_ = torch.floor(selected*torch.tensor([self.image.shape[1], self.image.shape[0]]).to(x.device).unsqueeze(0)).long()\n",
    "        output = torch.zeros(flattened_x.shape[0]).to(x.device)\n",
    "        output[mask] = (self.image.to(x.device)[self.image.shape[0]-1-x_[:,1], x_[:,0]]/torch.sum(self.image)).float()\n",
    "        return torch.log(.9995*output.reshape(x.shape[:-1]) + .0005*torch.exp(torch.distributions.MultivariateNormal(.5*torch.ones(2).to(x.device),10000*torch.eye(2).to(x.device)).log_prob(x)))\n",
    "target= image_2d_distribution('euler.jpg')\n",
    "# class TwoCircles():\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.means = torch.tensor([1.,2.])\n",
    "#         self.weights = torch.tensor([.5, .5])\n",
    "#         self.noise = torch.tensor([0.125])\n",
    "\n",
    "#     def sample(self,num_samples, joint = False):\n",
    "#         angle = torch.rand(num_samples)*2*math.pi\n",
    "#         cat = torch.distributions.Categorical(self.weights).sample(num_samples)\n",
    "#         x,y = self.means[cat]*torch.cos(angle) + torch.randn_like(angle)*self.noise,self.means[cat]*torch.sin(angle) + torch.randn_like(angle)*self.noise\n",
    "#         if not joint:\n",
    "#             return torch.cat([x.unsqueeze(-1),y.unsqueeze(-1)], dim =-1)\n",
    "#         else:\n",
    "#             return torch.cat([x.unsqueeze(-1),y.unsqueeze(-1)], dim =-1), cat\n",
    "\n",
    "#     def log_prob(self,x):\n",
    "#         r = torch.norm(x, dim=-1).unsqueeze(-1)\n",
    "#         cat = torch.distributions.Categorical(self.weights.to(x.device))\n",
    "#         mvn = torch.distributions.MultivariateNormal(self.means.to(x.device).unsqueeze(-1), torch.eye(1).to(x.device).unsqueeze(0).repeat(2,1,1)*self.noise.to(x.device))\n",
    "#         mixt = torch.distributions.MixtureSameFamily(cat, mvn)\n",
    "#         return mixt.log_prob(r)\n",
    "# class Orbits():\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         number_planets = 7\n",
    "#         covs_target = 0.04 * torch.eye(2).unsqueeze(0).repeat(number_planets, 1, 1)\n",
    "#         means_target = 2.5 * torch.view_as_real(\n",
    "#             torch.pow(torch.exp(torch.tensor([2j * 3.1415 / number_planets])), torch.arange(0, number_planets)))\n",
    "#         weights_target = torch.ones(number_planets)\n",
    "#         weights_target = weights_target\n",
    "\n",
    "#         mvn_target = torch.distributions.MultivariateNormal(means_target, covs_target)\n",
    "#         cat = torch.distributions.Categorical(torch.exp(weights_target) / torch.sum(torch.exp(weights_target)))\n",
    "#         self.mix_target = torch.distributions.MixtureSameFamily(cat, mvn_target)\n",
    "\n",
    "#     def sample(self, num_samples):\n",
    "#         number_planets = 7\n",
    "#         covs_target = 0.04 * torch.eye(2).unsqueeze(0).repeat(number_planets, 1, 1)\n",
    "#         means_target = 2.5 * torch.view_as_real(\n",
    "#             torch.pow(torch.exp(torch.tensor([2j * 3.1415 / number_planets])), torch.arange(0, number_planets)))\n",
    "#         weights_target = torch.ones(number_planets)\n",
    "\n",
    "#         mvn_target = torch.distributions.MultivariateNormal(means_target, covs_target)\n",
    "#         cat = torch.distributions.Categorical(torch.exp(weights_target) / torch.sum(torch.exp(weights_target)))\n",
    "#         return torch.distributions.MixtureSameFamily(cat, mvn_target).sample(num_samples)\n",
    "\n",
    "#     def log_prob(self,x):\n",
    "#         number_planets = 7\n",
    "#         covs_target = 0.04 * torch.eye(2).unsqueeze(0).repeat(number_planets, 1, 1)\n",
    "#         means_target = 2.5 * torch.view_as_real(\n",
    "#             torch.pow(torch.exp(torch.tensor([2j * 3.1415 / number_planets])), torch.arange(0, number_planets)))\n",
    "#         weights_target = torch.ones(number_planets).to(x.device)\n",
    "\n",
    "#         mvn_target = torch.distributions.MultivariateNormal(means_target.to(x.device), covs_target.to(x.device))\n",
    "#         cat = torch.distributions.Categorical(torch.exp(weights_target) / torch.sum(torch.exp(weights_target)))\n",
    "#         return torch.distributions.MixtureSameFamily(cat, mvn_target).log_prob(x)\n",
    "\n",
    "# target = Orbits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:18<00:00,  7.21it/s, DKL observed = 7.587201 DKL Latent = 7.585561 ; device: cuda]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "K = 10\n",
    "num_samples = 5000\n",
    "dif = DIFSampler(target.log_prob,2, K)\n",
    "dif.w = SoftmaxWeight(K,2, [128,128])\n",
    "dif.train(epochs,num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▉                                                                                                                                                                                                                | 23/1000 [02:10<1:32:14,  5.67s/it, DKL observed = 7.6012 DKL Latent = 7.601025 ; device: cuda]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\elouan\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_sampler.py:77\u001b[0m, in \u001b[0;36mDIFSampler.train\u001b[1;34m(self, epochs, num_samples, batch_size)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     74\u001b[0m     DKL_observed_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m     75\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDKL_observed(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader)])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     76\u001b[0m     DKL_latent_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m---> 77\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDKL_latent(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader)])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_values\u001b[38;5;241m.\u001b[39mappend(DKL_latent_values)\n\u001b[0;32m     79\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDKL observed = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(DKL_observed_values, \u001b[38;5;241m6\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m DKL Latent = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mround\u001b[39m(DKL_latent_values, \u001b[38;5;241m6\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ; device: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(device))\n",
      "File \u001b[1;32mc:\\users\\elouan\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_sampler.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     74\u001b[0m     DKL_observed_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m     75\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDKL_observed(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)) \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader)])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     76\u001b[0m     DKL_latent_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m---> 77\u001b[0m         [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDKL_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader)])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_values\u001b[38;5;241m.\u001b[39mappend(DKL_latent_values)\n\u001b[0;32m     79\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDKL observed = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(DKL_observed_values, \u001b[38;5;241m6\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m DKL Latent = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mround\u001b[39m(DKL_latent_values, \u001b[38;5;241m6\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ; device: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(device))\n",
      "File \u001b[1;32mc:\\users\\elouan\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_sampler.py:35\u001b[0m, in \u001b[0;36mDIFSampler.DKL_latent\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDKL_latent\u001b[39m(\u001b[38;5;28mself\u001b[39m,z):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference\u001b[38;5;241m.\u001b[39mlog_density(z) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy_log_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\users\\elouan\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_sampler.py:45\u001b[0m, in \u001b[0;36mDIFSampler.proxy_log_density\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproxy_log_density\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[0;32m     44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mbackward(z)\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogsumexp(torch\u001b[38;5;241m.\u001b[39mdiagonal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_log_v(x), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_log_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mlog_det_J(x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mimage_2d_distribution.log_prob\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m flattened_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, start_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, end_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     21\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlogical_and(torch\u001b[38;5;241m.\u001b[39mall(flattened_x\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),torch\u001b[38;5;241m.\u001b[39mall(flattened_x\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1\u001b[39m, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 22\u001b[0m selected \u001b[38;5;241m=\u001b[39m \u001b[43mflattened_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m x_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloor(selected\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     24\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(flattened_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dif.train(epochs,10*num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m linspace \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m     model_samples \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_to_visualize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     reference_samples \u001b[38;5;241m=\u001b[39m model_to_visualize\u001b[38;5;241m.\u001b[39mreference\u001b[38;5;241m.\u001b[39msample(num_samples)\n\u001b[0;32m      9\u001b[0m     x0_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(model_samples[:,\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\users\\elouan\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\dif_sampler.py:39\u001b[0m, in \u001b[0;36mDIFSampler.sample_model\u001b[1;34m(self, num_samples)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_samples):\n\u001b[0;32m     38\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference\u001b[38;5;241m.\u001b[39msample(num_samples)\n\u001b[1;32m---> 39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     pick \u001b[38;5;241m=\u001b[39m Categorical(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mlog_prob(z)))\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x[\u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), pick, :]\n",
      "File \u001b[1;32mc:\\users\\elouan\\pycharmprojects\\discretely-indexed-flows\\venv\\lib\\site-packages\\models_dif\\location_scale_flow.py:17\u001b[0m, in \u001b[0;36mLocationScaleFlow.backward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     15\u001b[0m desired_size\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK)\n\u001b[0;32m     16\u001b[0m Z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(desired_size)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mZ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_s\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m.\u001b[39mexpand_as(Z)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "###Visualize DIF sampler dimension 2 ###\n",
    "\n",
    "model_to_visualize = dif\n",
    "\n",
    "linspace = 200\n",
    "with torch.no_grad():\n",
    "    model_samples = model_to_visualize.sample_model(num_samples)\n",
    "    reference_samples = model_to_visualize.reference.sample(num_samples)\n",
    "    x0_min = min(model_samples[:,0])\n",
    "    x0_max = max(model_samples[:,0])\n",
    "    x1_min = min(model_samples[:,1])\n",
    "    x1_max = max(model_samples[:,1])\n",
    "    x_grid = torch.cartesian_prod(torch.linspace(x0_min, x0_max,linspace),torch.linspace(x1_min, x1_max,linspace))\n",
    "    density_model = torch.exp(model_to_visualize.model_log_density(x_grid).reshape(linspace,linspace))\n",
    "    density_target = torch.exp(model_to_visualize.target_log_density(x_grid).reshape(linspace,linspace))\n",
    "    z0_min = min(reference_samples[:,0])\n",
    "    z0_max = max(reference_samples[:,0])\n",
    "    z1_min = min(reference_samples[:,1])\n",
    "    z1_max = max(reference_samples[:,1])\n",
    "    z_grid = torch.cartesian_prod(torch.linspace(z0_min, z0_max,linspace),torch.linspace(z1_min, z1_max,linspace))\n",
    "    density_proxy = torch.exp(model_to_visualize.proxy_log_density(z_grid).reshape(linspace,linspace))\n",
    "    density_reference = torch.exp(model_to_visualize.reference.log_density(z_grid).reshape(linspace,linspace))\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "\n",
    "ax1 = fig.add_subplot(321)\n",
    "ax1.pcolormesh(torch.linspace(x0_min, x0_max,linspace),torch.linspace(x1_min, x1_max,linspace), density_target.T, cmap = red_cmap)\n",
    "\n",
    "ax2 = fig.add_subplot(322)\n",
    "ax2.pcolormesh(torch.linspace(z0_min, z0_max,linspace),torch.linspace(z1_min, z1_max,linspace), density_proxy.T, cmap = orange_cmap)\n",
    "\n",
    "ax3 = fig.add_subplot(323, sharex=ax1)\n",
    "ax3.scatter(model_samples[:,0], model_samples[:,1], alpha = 0.5,color=blue_color, label=\"Output model density\")\n",
    "\n",
    "ax4 = fig.add_subplot(324, sharex=ax2)\n",
    "ax4.scatter(reference_samples[:, 0],reference_samples[:, 1], alpha=0.5, color=green_color,label='Reference samples')\n",
    "\n",
    "ax5 = fig.add_subplot(325, sharex=ax1)\n",
    "ax5.pcolormesh(torch.linspace(x0_min, x0_max,linspace),torch.linspace(x1_min, x1_max,linspace), density_model.T, cmap = blue_cmap)\n",
    "\n",
    "ax6 = fig.add_subplot(326, sharex=ax2)\n",
    "ax6.pcolormesh(torch.linspace(z0_min, z0_max,linspace),torch.linspace(z1_min, z1_max,linspace), density_reference.T, cmap = green_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DUAN TMC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
